{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/herbert/.virtualenvs/wieling/lib/python3.5/site-packages/scikit_learn-0.19.0-py3.5-linux-x86_64.egg/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from ipy_progressbar import ProgressBar\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import mlab, pyplot, rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (25, 10)\n",
    "import librosa\n",
    "from jupyter_progressbar import ProgressBar\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Lambda, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from kapre.time_frequency import Spectrogram\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12386053361222617431, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 1253507072\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 10687157828282272591\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 22050\n",
    "seconds = sampling_rate * 5\n",
    "folder = '/home/herbert/RuG/youtube_classification/data2/'\n",
    "classes = [f for f in os.listdir(folder) if os.path.isdir(os.path.join(folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (label, os.path.join(folder, class_, filename))\n",
    "    for label, class_ in enumerate(classes)\n",
    "    for filename in os.listdir(os.path.join(folder, class_))\n",
    "    if filename.endswith('.wav')\n",
    "]\n",
    "train_data, test_data = train_test_split(data, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791ec9ed4f994dd88059ba88eba668f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='<b>0</b>s passed', placeholder='0%'))), HTML(value='<b>0</b>% or <b>0</b> of <b>0</b> done', placeholder='0%')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for label, filename in ProgressBar(test_data):\n",
    "    try:\n",
    "        audio, sr = librosa.load(filename)\n",
    "    except:\n",
    "        pass\n",
    "    leave = audio.shape[0] // seconds\n",
    "    if sr != sampling_rate or leave <= 0:\n",
    "        continue\n",
    "    X_test.append(audio[:leave * seconds].reshape(leave, seconds))\n",
    "    y_test.extend([label] * leave)\n",
    "\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "y_test = np.array(y_test)\n",
    "with open('test_data.p3', 'wb') as f:\n",
    "    pickle.dump((X_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95175f2047a640f9ba77a766698d1fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='<b>0</b>s passed', placeholder='0%'))), HTML(value='<b>0</b>% or <b>0</b> of <b>0</b> done', placeholder='0%')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 20\n",
    "for j in range(n):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i, (label, filename) in enumerate(ProgressBar(train_data[j::n])):\n",
    "        try:\n",
    "            audio, sr = librosa.load(filename)\n",
    "        except:\n",
    "            pass\n",
    "        leave = audio.shape[0] // seconds\n",
    "        if sr != sampling_rate or leave <= 0:\n",
    "            continue\n",
    "        X_train.append(audio[:leave * seconds].reshape(leave, seconds))\n",
    "        y_train.extend([label] * leave)\n",
    "\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    with open('train_data_{}.p3'.format(j), 'wb') as f:\n",
    "        pickle.dump((X_train, y_train), f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Layer (type)              Output Shape              Param #     \n",
      "================================================================================\n",
      "static_stft (Spectrogram) (None, 257, 431, 1)       263168      \n",
      "________________________________________________________________________________\n",
      "lambda_2 (Lambda)         (None, 257, 431, 1)       0           \n",
      "________________________________________________________________________________\n",
      "conv1 (Conv2D)            (None, 251, 425, 32)      1600        \n",
      "________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooli (None, 10, 25, 32)        0           \n",
      "________________________________________________________________________________\n",
      "dropout_1 (Dropout)       (None, 10, 25, 32)        0           \n",
      "________________________________________________________________________________\n",
      "conv2 (Conv2D)            (None, 1, 16, 32)         102432      \n",
      "________________________________________________________________________________\n",
      "dropout_2 (Dropout)       (None, 1, 16, 32)         0           \n",
      "________________________________________________________________________________\n",
      "flatten_2 (Flatten)       (None, 512)               0           \n",
      "________________________________________________________________________________\n",
      "dense_2 (Dense)           (None, 1)                 513         \n",
      "================================================================================\n",
      "Total params: 367,713\n",
      "Trainable params: 104,545\n",
      "Non-trainable params: 263,168\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# normalize spectogram output\n",
    "slope = K.variable(value=1/40)\n",
    "intercept = K.variable(value=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Spectrogram(n_dft=512, n_hop=256, input_shape=(1, seconds), \n",
    "          return_decibel_spectrogram=True, power_spectrogram=2.0, \n",
    "          trainable_kernel=False, name='static_stft'))\n",
    "model.add(Lambda(lambda x: slope * x + intercept))\n",
    "model.add(Conv2D(32, (7, 7), name='conv1', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((25, 17)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, (10, 10), name='conv2', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary(line_length=80, positions=[.33, .65, .8, 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data_0.p3', 'rb') as f:\n",
    "    X_train, y_train = pickle.load(f)\n",
    "with open('test_data.p3', 'rb') as f:\n",
    "    X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train = X_train[perm, :, :]\n",
    "y_train = y_train[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=optimizer,\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7170 samples, validate on 1334 samples\n",
      "Epoch 1/10\n",
      "7170/7170 [==============================] - 709s - loss: 0.6914 - acc: 0.5308 - val_loss: 0.7065 - val_acc: 0.4055\n",
      "Epoch 2/10\n",
      "7170/7170 [==============================] - 705s - loss: 0.6916 - acc: 0.5308 - val_loss: 0.7012 - val_acc: 0.4055\n",
      "Epoch 3/10\n",
      "7170/7170 [==============================] - 716s - loss: 0.6915 - acc: 0.5308 - val_loss: 0.7138 - val_acc: 0.4055\n",
      "Epoch 4/10\n",
      "7170/7170 [==============================] - 725s - loss: 0.6915 - acc: 0.5308 - val_loss: 0.7132 - val_acc: 0.4055\n",
      "Epoch 5/10\n",
      "7170/7170 [==============================] - 763s - loss: 0.6918 - acc: 0.5308 - val_loss: 0.6998 - val_acc: 0.4055\n",
      "Epoch 6/10\n",
      "7170/7170 [==============================] - 699s - loss: 0.6916 - acc: 0.5308 - val_loss: 0.7092 - val_acc: 0.4055\n",
      "Epoch 7/10\n",
      "7170/7170 [==============================] - 693s - loss: 0.6915 - acc: 0.5286 - val_loss: 0.7009 - val_acc: 0.4055\n",
      "Epoch 8/10\n",
      "7170/7170 [==============================] - 707s - loss: 0.6917 - acc: 0.5308 - val_loss: 0.7017 - val_acc: 0.4055\n",
      "Epoch 9/10\n",
      "7170/7170 [==============================] - 3388s - loss: 0.6916 - acc: 0.5308 - val_loss: 0.7089 - val_acc: 0.4055\n",
      "Epoch 10/10\n",
      "7170/7170 [==============================] - 11080s - loss: 0.6916 - acc: 0.5308 - val_loss: 0.7087 - val_acc: 0.4055\n"
     ]
    }
   ],
   "source": [
    "# ss = np.random.rand(X_train.shape[0]) < 0.01\n",
    "# ss2 = np.random.rand(X_test.shape[0]) < 0.01\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7170 samples, validate on 1334 samples\n",
      "Epoch 1/10\n",
      "2880/7170 [===========>..................] - ETA: 388s - loss: 0.6917 - acc: 0.5302"
     ]
    }
   ],
   "source": [
    "# ss = np.random.rand(X_train.shape[0]) < 0.01\n",
    "# ss2 = np.random.rand(X_test.shape[0]) < 0.01\n",
    "\n",
    "history2 = model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
